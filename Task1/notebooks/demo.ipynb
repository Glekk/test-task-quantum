{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from datasets import load_from_disk\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\") # Adds higher directory to path (temporarily) to access our modules\n",
    "from src.inference import main as inference\n",
    "from src.train import tokenize_and_align_labels, compute_metrics_extra_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up some constants (loading from .env file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LOCAL_DATASET_PATH = os.getenv('LOCAL_DATASET_PATH')\n",
    "CHECKPOINT_PATH = os.getenv('CHECKPOINT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating our models (I trained bert-base and bert-large) on train, val and test data to see final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_all_sets(dataset_path, model_path):\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    tokenized_ds = dataset.map(tokenize_and_align_labels, \n",
    "                        batched=True,\n",
    "                        remove_columns=dataset['train'].column_names,\n",
    "                        fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "    label_names = ['O', 'B-MOUNT', 'I-MOUNT']\n",
    "    label2id = {label: i for i, label in enumerate(label_names)}\n",
    "    id2label = {label: i for i, label in label2id.items()}\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=CHECKPOINT_PATH,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        logging_strategy='no',\n",
    "    )\n",
    "\n",
    "    metric = evaluate.load('seqeval')\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=tokenized_ds['train'],\n",
    "        eval_dataset=tokenized_ds['val'],\n",
    "        data_collator=data_collator,\n",
    "        processing_class=tokenizer,\n",
    "        compute_metrics=compute_metrics_extra_args(metric, id2label)\n",
    "    )\n",
    "\n",
    "    res_train = trainer.evaluate(tokenized_ds['train'])\n",
    "    res_val = trainer.evaluate(tokenized_ds['val'])\n",
    "    res_test = trainer.evaluate(tokenized_ds['test'])\n",
    "\n",
    "    return res_train, res_val, res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base = '../models/bert-finetuned-NER'\n",
    "bert_large = '../models/bert-large-finetuned-NER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:04<00:00, 2378.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 07:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_train_base, res_val_base, res_test_base = evaluate_on_all_sets(LOCAL_DATASET_PATH, bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 19:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_train_large, res_val_large, res_test_large = evaluate_on_all_sets(LOCAL_DATASET_PATH, bert_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.052447</td>\n",
       "      <td>0.054503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.769197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.911282</td>\n",
       "      <td>0.831512</td>\n",
       "      <td>0.830727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.899378</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.798779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.994210</td>\n",
       "      <td>0.983945</td>\n",
       "      <td>0.982885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>207.303800</td>\n",
       "      <td>130.359800</td>\n",
       "      <td>127.922300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>144.715000</td>\n",
       "      <td>76.711000</td>\n",
       "      <td>78.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>18.089000</td>\n",
       "      <td>9.589000</td>\n",
       "      <td>9.772000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  train         val        test\n",
       "eval_loss                      0.017100    0.052447    0.054503\n",
       "eval_model_preparation_time    0.002000    0.002000    0.002000\n",
       "eval_precision                 0.887781    0.776042    0.769197\n",
       "eval_recall                    0.911282    0.831512    0.830727\n",
       "eval_f1                        0.899378    0.802820    0.798779\n",
       "eval_accuracy                  0.994210    0.983945    0.982885\n",
       "eval_runtime                 207.303800  130.359800  127.922300\n",
       "eval_samples_per_second      144.715000   76.711000   78.172000\n",
       "eval_steps_per_second         18.089000    9.589000    9.772000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_base = pd.DataFrame.from_dict(res_train_base, orient='index', columns=['train'])\n",
    "df_val_base = pd.DataFrame.from_dict(res_val_base, orient='index', columns=['val'])\n",
    "df_test_base = pd.DataFrame.from_dict(res_test_base, orient='index', columns=['test'])\n",
    "\n",
    "all_res_base = pd.concat([df_train_base, df_val_base, df_test_base], axis=1)\n",
    "all_res_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.050208</td>\n",
       "      <td>0.052177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.938637</td>\n",
       "      <td>0.817246</td>\n",
       "      <td>0.813042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.932396</td>\n",
       "      <td>0.846650</td>\n",
       "      <td>0.844976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.935506</td>\n",
       "      <td>0.831688</td>\n",
       "      <td>0.828702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.996643</td>\n",
       "      <td>0.985701</td>\n",
       "      <td>0.985128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>470.077700</td>\n",
       "      <td>339.036900</td>\n",
       "      <td>346.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>63.819000</td>\n",
       "      <td>29.495000</td>\n",
       "      <td>28.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>7.977000</td>\n",
       "      <td>3.687000</td>\n",
       "      <td>3.607000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  train         val        test\n",
       "eval_loss                      0.010216    0.050208    0.052177\n",
       "eval_model_preparation_time    0.004000    0.004000    0.004000\n",
       "eval_precision                 0.938637    0.817246    0.813042\n",
       "eval_recall                    0.932396    0.846650    0.844976\n",
       "eval_f1                        0.935506    0.831688    0.828702\n",
       "eval_accuracy                  0.996643    0.985701    0.985128\n",
       "eval_runtime                 470.077700  339.036900  346.532100\n",
       "eval_samples_per_second       63.819000   29.495000   28.857000\n",
       "eval_steps_per_second          7.977000    3.687000    3.607000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_large = pd.DataFrame.from_dict(res_train_large, orient='index', columns=['train'])\n",
    "df_val_large = pd.DataFrame.from_dict(res_val_large, orient='index', columns=['val'])\n",
    "df_test_large = pd.DataFrame.from_dict(res_test_large, orient='index', columns=['test'])\n",
    "\n",
    "all_res_large = pd.concat([df_train_large, df_val_large, df_test_large], axis=1)\n",
    "all_res_large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results are not bad, but there is a lot of room for improvement.\n",
    "Also, bert-large as expected yields better results than bert-base, especially in terms of presicion. It is about 0.04-0.05 higher than bert-base that is also resulting in higher f1-score.\n",
    "Worth mentioning that bert-large is about 2 times slower than bert-base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of inference (using bert-large fine-tuned model)\n",
    "I found quite big dataset for training and decided to stick with it, but I also tried to use ChatGPT for data creation and generated some samples.  \n",
    "Lets use them as examples for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The history and cultural significance of Denali are well-documented.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv('mountain_ner_examples.csv')\n",
    "csv = csv['tokens'].tolist()\n",
    "csv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Lhotse is part of a mountain range that spans several countries.\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: L, Start: 0, End: 1\n",
      "Entity: B-MOUNT, Score: 0.9991176724433899\n",
      "\n",
      "Word: ##hot, Start: 1, End: 4\n",
      "Entity: I-MOUNT, Score: 0.9998487234115601\n",
      "\n",
      "Word: ##se, Start: 4, End: 6\n",
      "Entity: I-MOUNT, Score: 0.999747097492218\n",
      "\n",
      "-----------------------\n",
      "Mount Elbrus has been the site of numerous scientific expeditions over the years.\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Mount, Start: 0, End: 5\n",
      "Entity: B-MOUNT, Score: 0.9997310042381287\n",
      "\n",
      "Word: El, Start: 6, End: 8\n",
      "Entity: I-MOUNT, Score: 0.9998530149459839\n",
      "\n",
      "Word: ##b, Start: 8, End: 9\n",
      "Entity: I-MOUNT, Score: 0.9998550415039062\n",
      "\n",
      "Word: ##rus, Start: 9, End: 12\n",
      "Entity: I-MOUNT, Score: 0.999805748462677\n",
      "\n",
      "-----------------------\n",
      "The ascent of Nanga Parbat requires careful preparation and skill.\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Nan, Start: 14, End: 17\n",
      "Entity: B-MOUNT, Score: 0.9980646967887878\n",
      "\n",
      "Word: ##ga, Start: 17, End: 19\n",
      "Entity: I-MOUNT, Score: 0.9993358254432678\n",
      "\n",
      "Word: Pa, Start: 20, End: 22\n",
      "Entity: I-MOUNT, Score: 0.9996610879898071\n",
      "\n",
      "Word: ##rb, Start: 22, End: 24\n",
      "Entity: I-MOUNT, Score: 0.9996837377548218\n",
      "\n",
      "Word: ##at, Start: 24, End: 26\n",
      "Entity: I-MOUNT, Score: 0.9996525049209595\n",
      "\n",
      "-----------------------\n",
      "One of the most iconic peaks in the world, Kangchenjunga stands tall as a natural wonder.\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Kang, Start: 43, End: 47\n",
      "Entity: B-MOUNT, Score: 0.9992875456809998\n",
      "\n",
      "Word: ##chen, Start: 47, End: 51\n",
      "Entity: I-MOUNT, Score: 0.9996626377105713\n",
      "\n",
      "Word: ##jun, Start: 51, End: 54\n",
      "Entity: I-MOUNT, Score: 0.9996095299720764\n",
      "\n",
      "Word: ##ga, Start: 54, End: 56\n",
      "Entity: I-MOUNT, Score: 0.999241828918457\n",
      "\n",
      "-----------------------\n",
      "Many stories have been told about the treacherous conditions on Mount Kosciuszko.\n",
      "-----------------------\n",
      "Word: Mount, Start: 64, End: 69\n",
      "Entity: B-MOUNT, Score: 0.9967331886291504\n",
      "\n",
      "Word: Ko, Start: 70, End: 72\n",
      "Entity: I-MOUNT, Score: 0.9972622394561768\n",
      "\n",
      "Word: ##s, Start: 72, End: 73\n",
      "Entity: I-MOUNT, Score: 0.9997381567955017\n",
      "\n",
      "Word: ##cius, Start: 73, End: 77\n",
      "Entity: I-MOUNT, Score: 0.9997338652610779\n",
      "\n",
      "Word: ##z, Start: 77, End: 78\n",
      "Entity: I-MOUNT, Score: 0.9995952248573303\n",
      "\n",
      "Word: ##ko, Start: 78, End: 80\n",
      "Entity: I-MOUNT, Score: 0.9996440410614014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "indexes = np.random.randint(0, len(csv), 5)\n",
    "for i in indexes:\n",
    "    example = csv[i]\n",
    "    print('-----------------------')\n",
    "    print(example)\n",
    "    print('-----------------------')\n",
    "\n",
    "    inference(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see model works well on this examples, now lets try hard example.\n",
    "I asked ChatGPT to generate hard example for us, lets see how our model will perform on it.\n",
    "(This sentence uses less prominent Colorado 14ers that could challenge NER models since \"Wilson\" and \"Antero\" could be mistaken for person names, while \"Blanca\" could be confused with a given name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Wilson, Start: 17, End: 23\n",
      "Entity: B-MOUNT, Score: 0.8673344254493713\n",
      "\n",
      "Word: Peak, Start: 24, End: 28\n",
      "Entity: I-MOUNT, Score: 0.8126006126403809\n",
      "\n",
      "Word: Mount, Start: 42, End: 47\n",
      "Entity: B-MOUNT, Score: 0.9360774755477905\n",
      "\n",
      "Word: El, Start: 48, End: 50\n",
      "Entity: I-MOUNT, Score: 0.9280115365982056\n",
      "\n",
      "Word: ##bert, Start: 50, End: 54\n",
      "Entity: I-MOUNT, Score: 0.933672308921814\n",
      "\n",
      "Word: Blanc, Start: 59, End: 64\n",
      "Entity: B-MOUNT, Score: 0.8041844964027405\n",
      "\n",
      "Word: ##a, Start: 64, End: 65\n",
      "Entity: I-MOUNT, Score: 0.8239085078239441\n",
      "\n",
      "Word: Peak, Start: 66, End: 70\n",
      "Entity: I-MOUNT, Score: 0.7228032350540161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = \"The lesser-known Wilson Peak looms beside Mount Elbert and Blanca Peak, while distant Antero and Shavano pierce the Colorado skyline.\"\n",
    "inference(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that our model did not catch all the entities (it missed Antero and Shavano), but it found other three mountains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
